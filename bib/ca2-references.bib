
@article{terletzky_semi-automated_2014,
	title = {A {Semi}-{Automated} {Single} {Day} {Image} {Differencing} {Technique} to {Identify} {Animals} in {Aerial} {Imagery}},
	volume = {9},
	url = {http://dx.doi.org/10.1371/journal.pone.0085239},
	doi = {10.1371/journal.pone.0085239},
	abstract = {Our research presents a proof-of-concept that explores a new and innovative method to identify large animals in aerial imagery with single day image differencing. We acquired two aerial images of eight fenced pastures and conducted a principal component analysis of each image. We then subtracted the first principal component of the two pasture images followed by heuristic thresholding to generate polygons. The number of polygons represented the number of potential cattle (Bos taurus) and horses (Equus caballus) in the pasture. The process was considered semi-automated because we were not able to automate the identification of spatial or spectral thresholding values. Imagery was acquired concurrently with ground counts of animal numbers. Across the eight pastures, 82\% of the animals were correctly identified, mean percent commission was 53\%, and mean percent omission was 18\%. The high commission error was due to small mis-alignments generated from image-to-image registration, misidentified shadows, and grouping behavior of animals. The high probability of correctly identifying animals suggests short time interval image differencing could provide a new technique to enumerate wild ungulates occupying grassland ecosystems, especially in isolated or difficult to access areas. To our knowledge, this was the first attempt to use standard change detection techniques to identify and enumerate large ungulates.},
	number = {1},
	urldate = {2014-01-22},
	journal = {PLoS ONE},
	author = {Terletzky, Pat and Ramsey, Robert Douglas},
	month = jan,
	year = {2014},
	note = {00000},
	pages = {e85239},
	file = {PLoS Snapshot:/Users/kirk/Zotero/storage/U6R8TGFJ/infodoi10.1371journal.pone.html:text/html;Terletzky and Ramsey - 2014 - A Semi-Automated Single Day Image Differencing Tec.pdf:/Users/kirk/Zotero/storage/PJKT5U9W/Terletzky and Ramsey - 2014 - A Semi-Automated Single Day Image Differencing Tec.pdf:application/pdf},
}

@article{cui_class-balanced_nodate,
	title = {Class-{Balanced} {Loss} {Based} on {Effective} {Number} of {Samples}},
	abstract = {With the rapid increase of large-scale, real-world datasets, it becomes critical to address the problem of longtailed data distribution (i.e., a few classes account for most of the data, while most classes are under-represented). Existing solutions typically adopt class re-balancing strategies such as re-sampling and re-weighting based on the number of observations for each class. In this work, we argue that as the number of samples increases, the additional beneﬁt of a newly added data point will diminish. We introduce a novel theoretical framework to measure data overlap by associating with each sample a small neighboring region rather than a single point. The effective number of samples is deﬁned as the volume of samples and can be calculated by a simple formula (1−βn)/(1−β), where n is the number of samples and β ∈ [0, 1) is a hyperparameter. We design a re-weighting scheme that uses the effective number of samples for each class to re-balance the loss, thereby yielding a class-balanced loss. Comprehensive experiments are conducted on artiﬁcially induced long-tailed CIFAR datasets and large-scale datasets including ImageNet and iNaturalist. Our results show that when trained with the proposed class-balanced loss, the network is able to achieve signiﬁcant performance gains on long-tailed datasets.},
	language = {en},
	author = {Cui, Yin and Jia, Menglin and Lin, Tsung-Yi and Song, Yang and Belongie, Serge},
	pages = {10},
	file = {Cui et al. - Class-Balanced Loss Based on Effective Number of S.pdf:/Users/kirk/Zotero/storage/3RVA4X2M/Cui et al. - Class-Balanced Loss Based on Effective Number of S.pdf:application/pdf},
}

@article{kellenberger_half_2019,
	title = {Half a {Percent} of {Labels} is {Enough}: {Efficient} {Animal} {Detection} in {UAV} {Imagery} {Using} {Deep} {CNNs} and {Active} {Learning}},
	volume = {57},
	issn = {1558-0644},
	shorttitle = {Half a {Percent} of {Labels} is {Enough}},
	doi = {10.1109/TGRS.2019.2927393},
	abstract = {We present an Active Learning (AL) strategy for reusing a deep Convolutional Neural Network (CNN)-based object detector on a new data set. This is of particular interest for wildlife conservation: given a set of images acquired with an Unmanned Aerial Vehicle (UAV) and manually labeled ground truth, our goal is to train an animal detector that can be reused for repeated acquisitions, e.g., in follow-up years. Domain shifts between data sets typically prevent such a direct model application. We thus propose to bridge this gap using AL and introduce a new criterion called Transfer Sampling (TS). TS uses Optimal Transport (OT) to find corresponding regions between the source and the target data sets in the space of CNN activations. The CNN scores in the source data set are used to rank the samples according to their likelihood of being animals, and this ranking is transferred to the target data set. Unlike conventional AL criteria that exploit model uncertainty, TS focuses on very confident samples, thus allowing quick retrieval of true positives in the target data set, where positives are typically extremely rare and difficult to find by visual inspection. We extend TS with a new window cropping strategy that further accelerates sample retrieval. Our experiments show that with both strategies combined, less than half a percent of oracle-provided labels are enough to find almost 80\% of the animals in challenging sets of UAV images, beating all baselines by a margin.},
	number = {12},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Kellenberger, Benjamin and Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
	month = dec,
	year = {2019},
	keywords = {Biological system modeling, ecology, learning (artificial intelligence), wildlife conservation, Animals, object detection, Active Learning (AL), active learning strategy, Adaptation models, animal census, animal detection, animal detector, autonomous aerial vehicles, CNN activations, convolutional neural nets, convolutional neural networks, Data models, deep convolutional neural network-based object detector, Detectors, domain adaptation, environmental science computing, mobile robots, optimal transport, Optimal Transport (OT), Predictive models, sample retrieval, transfer sampling, UAV imagery, unmanned aerial vehicles, Unmanned aerial vehicles, window cropping strategy},
	pages = {9524--9533},
	file = {Kellenberger et al 2019 - Half a Percent of Labels is Enough.pdf:/Users/kirk/Zotero/storage/Q22RXWCP/Kellenberger et al 2019 - Half a Percent of Labels is Enough.pdf:application/pdf},
}

@article{mcclure_automated_2018,
	title = {Automated monitoring for birds in flight: {Proof} of concept with eagles at a wind power facility},
	volume = {224},
	issn = {0006-3207},
	shorttitle = {Automated monitoring for birds in flight},
	url = {http://www.sciencedirect.com/science/article/pii/S0006320717319407},
	doi = {10.1016/j.biocon.2018.04.041},
	abstract = {Automated surveys for wildlife have the potential to improve data collection while averting mortality of animals. Collisions of eagles at wind power facilities are particularly of concern and therefore an automated system that could detect birds, determine if they are eagles, and track their movement, might aid in curtailing wind turbines before collisions occur. Here, we use human observers and photographs to test the ability of a camera-based monitoring system, called IdentiFlight, to detect, classify, and track birds. IdentiFlight detected 96\% of the bird flights detected by observers and detected 562\% more birds than did observers. The discrepancy between observers and IdentiFlight seemed to be because the ability of observers to detect birds declined sharply by distance and toward the west. We reviewed photographs taken by IdentiFlight and determined that IdentiFlight misclassified nine of 149 eagles as non-eagles for a false negative rate of 6\%, and 287 of 1013 non-eagles as eagles for a false positive rate of 28\%. The median distance at classification for birds classified as eagles was 793 m and the median time from detection till classification was 0.4 s. Collectively, our results suggest that automated cameras can be effective means of detecting birds in flight and identifying eagles.},
	language = {en},
	urldate = {2020-03-06},
	journal = {Biological Conservation},
	author = {McClure, Christopher J. W. and Martinson, Luke and Allison, Taber D.},
	month = aug,
	year = {2018},
	keywords = {Bald eagle, Bird monitoring, Golden eagle, Renewable energy, Wind farm, Wind power},
	pages = {26--33},
	file = {McClure et al 2018 - Automated monitoring for birds in flight.pdf:/Users/kirk/Zotero/storage/FGEP6YSI/McClure et al 2018 - Automated monitoring for birds in flight.pdf:application/pdf;ScienceDirect Snapshot:/Users/kirk/Zotero/storage/D7GBN7HG/S0006320717319407.html:text/html},
}

@article{xu_automated_2020,
	title = {Automated cattle counting using {Mask} {R}-{CNN} in quadcopter vision system},
	volume = {171},
	issn = {0168-1699},
	url = {http://www.sciencedirect.com/science/article/pii/S0168169919320149},
	doi = {10.1016/j.compag.2020.105300},
	abstract = {The accurate and reliable counting of animals in quadcopter acquired imagery is one of the most promising but challenging tasks in intelligent livestock management in the future. In this paper we demonstrate the application of the cutting-edge instance segmentation framework, Mask R-CNN, in the context of cattle counting in different situations such as extensive production pastures and also in intensive housing such as feedlots. The optimal IoU threshold (0.5) and the full-appearance detection for the algorithm in this study are verified through performance evaluation. Experimental results in this research show the framework’s potential to perform reliably in offline quadcopter vision systems with an accuracy of 94\% in counting cattle on pastures and 92\% in feedlots. Compared with the existing typical competing algorithms, Mask R-CNN outperforms both in the counting accuracy and average precision especially on the datasets with occlusion and overlapping. Our research shows promising steps towards the incorporation of artificial intelligence using quadcopters for enhanced management of animals.},
	language = {en},
	urldate = {2020-03-06},
	journal = {Computers and Electronics in Agriculture},
	author = {Xu, Beibei and Wang, Wensheng and Falzon, Greg and Kwan, Paul and Guo, Leifeng and Chen, Guipeng and Tait, Amy and Schneider, Derek},
	month = apr,
	year = {2020},
	keywords = {Deep learning, Remote monitoring, Livestock management, Object detection, Quadcopter vision system},
	pages = {105300},
	file = {ScienceDirect Snapshot:/Users/kirk/Zotero/storage/ACGF2IH2/S0168169919320149.html:text/html;Xu et al 2020 - Automated cattle counting using Mask R-CNN in quadcopter vision system.pdf:/Users/kirk/Zotero/storage/UMD2B64Q/Xu et al 2020 - Automated cattle counting using Mask R-CNN in quadcopter vision system.pdf:application/pdf},
}

@article{bird_statistical_2014,
	title = {Statistical solutions for error and bias in global citizen science datasets},
	volume = {173},
	issn = {0006-3207},
	url = {http://www.sciencedirect.com/science/article/pii/S0006320713002693},
	doi = {10.1016/j.biocon.2013.07.037},
	abstract = {Networks of citizen scientists (CS) have the potential to observe biodiversity and species distributions at global scales. Yet the adoption of such datasets in conservation science may be hindered by a perception that the data are of low quality. This perception likely stems from the propensity of data generated by CS to contain greater levels of variability (e.g., measurement error) or bias (e.g., spatio-temporal clustering) in comparison to data collected by scientists or instruments. Modern analytical approaches can account for many types of error and bias typical of CS datasets. It is possible to (1) describe how pseudo-replication in sampling influences the overall variability in response data using mixed-effects modeling, (2) integrate data to explicitly model the sampling process and account for bias using a hierarchical modeling framework, and (3) examine the relative influence of many different or related explanatory factors using machine learning tools. Information from these modeling approaches can be used to predict species distributions and to estimate biodiversity. Even so, achieving the full potential from CS projects requires meta-data describing the sampling process, reference data to allow for standardization, and insightful modeling suitable to the question of interest.},
	journal = {Biological Conservation},
	author = {Bird, Tomas J. and Bates, Amanda E. and Lefcheck, Jonathan S. and Hill, Nicole A. and Thomson, Russell J. and Edgar, Graham J. and Stuart-Smith, Rick D. and Wotherspoon, Simon and Krkosek, Martin and Stuart-Smith, Jemina F. and Pecl, Gretta T. and Barrett, Neville and Frusher, Stewart},
	month = may,
	year = {2014},
	keywords = {Biodiversity, Additive models, Experimental design, Linear models, Reef life survey, Species distribution models, Statistical analysis, Volunteer data},
	pages = {144--154},
	file = {Bird et al-2014-Statistical solutions for error and bias in global citizen science datasets.pdf:/Users/kirk/Zotero/storage/ZWHITF8X/Bird et al-2014-Statistical solutions for error and bias in global citizen science datasets.pdf:application/pdf;ScienceDirect Snapshot:/Users/kirk/Zotero/storage/HJAT4U6T/S0006320713002693.html:text/html},
}

@article{kobler_identifying_2000,
	title = {Identifying brown bear habitat by a combined {GIS} and machine learning method},
	volume = {135},
	number = {2-3},
	journal = {Ecological Modelling},
	author = {Kobler, Andrej and Adamic, Miha},
	year = {2000},
	pages = {291--300},
	file = {Snapshot:/Users/kirk/Zotero/storage/JEX43CGJ/S0304380000003847.html:text/html},
}

@article{ofli_combining_2016,
	title = {Combining human computing and machine learning to make sense of big (aerial) data for disaster response},
	volume = {4},
	number = {1},
	journal = {Big data},
	author = {Ofli, Ferda and Meier, Patrick and Imran, Muhammad and Castillo, Carlos and Tuia, Devis and Rey, Nicolas and Briant, Julien and Millet, Pauline and Reinhard, Friedrich and Parkan, Matthew},
	year = {2016},
	pages = {47--59},
	file = {Ofli et al-2016-Combining human computing and machine learning to make sense of big (aerial).pdf:/Users/kirk/Zotero/storage/BBF2Y3SN/Ofli et al-2016-Combining human computing and machine learning to make sense of big (aerial).pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/ZM84P6K5/big.2014.html:text/html},
}

@techreport{rey_combining_2016,
	title = {Combining {UAV}-imagery and machine learning for wildlife conservation},
	author = {Rey, Nicolas},
	year = {2016},
	file = {Fulltext:/Users/kirk/Zotero/storage/YXRPYGEU/Rey - 2016 - Combining UAV-imagery and machine learning for wil.pdf:application/pdf;Rey-2016-Combining UAV-imagery and machine learning for wildlife conservation.pdf:/Users/kirk/Zotero/storage/CX2U9RJQ/Rey-2016-Combining UAV-imagery and machine learning for wildlife conservation.pdf:application/pdf},
}

@inproceedings{maire_automating_2015,
	title = {Automating marine mammal detection in aerial images captured during wildlife surveys: a deep learning approach},
	shorttitle = {Automating marine mammal detection in aerial images captured during wildlife surveys},
	booktitle = {Australasian {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {Springer},
	author = {Maire, Frederic and Alvarez, Luis Mejias and Hodgson, Amanda},
	year = {2015},
	pages = {379--385},
	file = {Maire et al-2015-Automating marine mammal detection in aerial images captured during wildlife.pdf:/Users/kirk/Zotero/storage/8U9BVCWG/Maire et al-2015-Automating marine mammal detection in aerial images captured during wildlife.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/MWTG98YS/978-3-319-26350-2_33.html:text/html},
}

@techreport{brunton_automatic_2018,
	title = {Automatic optical detection and classification of marine animals around {MHK} converters using machine vision},
	url = {https://www.osti.gov/biblio/1416953},
	abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
	language = {English},
	number = {DOE-UW-0006785},
	urldate = {2018-02-27},
	institution = {Univ. of Washington, Seattle, WA (United States)},
	author = {Brunton, Steven},
	month = jan,
	year = {2018},
	doi = {10.2172/1416953},
	file = {Brunton-2018-Automatic optical detection and classification of marine animals around MHK.pdf:/Users/kirk/Zotero/storage/69VIV8D7/Brunton-2018-Automatic optical detection and classification of marine animals around MHK.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/T2J7XWZU/1416953.html:text/html},
}

@inproceedings{elias_wheres_2017,
	title = {Where's the {Bear}?-{Automating} {Wildlife} {Image} {Processing} {Using} {IoT} and {Edge} {Cloud} {Systems}},
	shorttitle = {Where's the {Bear}?},
	booktitle = {Internet-of-{Things} {Design} and {Implementation} ({IoTDI}), 2017 {IEEE}/{ACM} {Second} {International} {Conference} on},
	publisher = {IEEE},
	author = {Elias, Andy Rosales and Golubovic, Nevena and Krintz, Chandra and Wolski, Rich},
	year = {2017},
	pages = {247--258},
	file = {Elias et al-2017-Where's the Bear.pdf:/Users/kirk/Zotero/storage/WPUZXLNA/Elias et al-2017-Where's the Bear.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/9U4RW43A/7946882.html:text/html},
}

@article{karnowski_automated_2016,
	title = {Automated video surveillance for the study of marine mammal behavior and cognition},
	volume = {3},
	number = {4},
	journal = {Animal Behavior and Cognition},
	author = {Karnowski, J. and Johnson, C. and Hutchins, E.},
	year = {2016},
	pages = {255--264},
	file = {Fulltext:/Users/kirk/Zotero/storage/I8ZQC298/Karnowski et al. - 2016 - Automated video surveillance for the study of mari.pdf:application/pdf;Karnowski et al-2016-Automated video surveillance for the study of marine mammal behavior and.pdf:/Users/kirk/Zotero/storage/FJMBUTZE/Karnowski et al-2016-Automated video surveillance for the study of marine mammal behavior and.pdf:application/pdf},
}

@article{moreland_evaluation_2015,
	title = {Evaluation of a ship-based unoccupied aircraft system ({UAS}) for surveys of spotted and ribbon seals in the {Bering} {Sea} pack ice},
	volume = {3},
	number = {3},
	journal = {Journal of Unmanned Vehicle Systems},
	author = {Moreland, Erin E. and Cameron, Michael F. and Angliss, Robyn P. and Boveng, Peter L.},
	year = {2015},
	pages = {114--122},
	file = {Fulltext:/Users/kirk/Zotero/storage/UIGHPAUR/juvs-2015-0012@juvs-vi.2016.01.html:text/html;Snapshot:/Users/kirk/Zotero/storage/QN6NPWMQ/juvs-2015-0012@juvs-vi.2016.01.html:text/html},
}

@article{torney_assessing_2016,
	title = {Assessing {Rotation}-{Invariant} {Feature} {Classification} for {Automated} {Wildebeest} {Population} {Counts}},
	volume = {11},
	issn = {1932-6203},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0156342},
	doi = {10.1371/journal.pone.0156342},
	abstract = {Accurate and on-demand animal population counts are the holy grail for wildlife conservation organizations throughout the world because they enable fast and responsive adaptive management policies. While the collection of image data from camera traps, satellites, and manned or unmanned aircraft has advanced significantly, the detection and identification of animals within images remains a major bottleneck since counting is primarily conducted by dedicated enumerators or citizen scientists. Recent developments in the field of computer vision suggest a potential resolution to this issue through the use of rotation-invariant object descriptors combined with machine learning algorithms. Here we implement an algorithm to detect and count wildebeest from aerial images collected in the Serengeti National Park in 2009 as part of the biennial wildebeest count. We find that the per image error rates are greater than, but comparable to, two separate human counts. For the total count, the algorithm is more accurate than both manual counts, suggesting that human counters have a tendency to systematically over or under count images. While the accuracy of the algorithm is not yet at an acceptable level for fully automatic counts, our results show this method is a promising avenue for further research and we highlight specific areas where future research should focus in order to develop fast and accurate enumeration of aerial count data. If combined with a bespoke image collection protocol, this approach may yield a fully automated wildebeest count in the near future.},
	number = {5},
	urldate = {2016-05-27},
	journal = {PLOS ONE},
	author = {Torney, Colin J. and Dobson, Andrew P. and Borner, Felix and Lloyd-Jones, David J. and Moyer, David and Maliti, Honori T. and Mwita, Machoke and Fredrick, Howard and Borner, Markus and Hopcraft, J. Grant C.},
	month = may,
	year = {2016},
	keywords = {Conservation science, Cameras, Wildebeest, Algorithms, Animal performance, Fourier analysis, Imaging techniques, Machine learning algorithms},
	pages = {e0156342},
	file = {Snapshot:/Users/kirk/Zotero/storage/A6ZDLSG4/article.html:text/html;Snapshot:/Users/kirk/Zotero/storage/3UDTBGAT/article.html:text/html;Torney et al_2016_Assessing Rotation-Invariant Feature Classification for Automated Wildebeest.pdf:/Users/kirk/Zotero/storage/Q9X5XMFQ/Torney et al_2016_Assessing Rotation-Invariant Feature Classification for Automated Wildebeest.pdf:application/pdf;Torney et al_2016_Assessing Rotation-Invariant Feature Classification for Automated Wildebeest.pdf:/Users/kirk/Zotero/storage/PF4BPEMD/Torney et al_2016_Assessing Rotation-Invariant Feature Classification for Automated Wildebeest.pdf:application/pdf},
}

@article{longmore_adapting_2017,
	title = {Adapting astronomical source detection software to help detect animals in thermal images obtained by unmanned aerial systems},
	url = {http://arxiv.org/abs/1701.01611},
	abstract = {In this paper we describe an unmanned aerial system equipped with a thermal-infrared camera and software pipeline that we have developed to monitor animal populations for conservation purposes. Taking a multi-disciplinary approach to tackle this problem, we use freely available astronomical source detection software and the associated expertise of astronomers, to efficiently and reliably detect humans and animals in aerial thermal-infrared footage. Combining this astronomical detection software with existing machine learning algorithms into a single, automated, end-to-end pipeline, we test the software using aerial video footage taken in a controlled, field-like environment. We demonstrate that the pipeline works reliably and describe how it can be used to estimate the completeness of different observational datasets to objects of a given type as a function of height, observing conditions etc. -- a crucial step in converting video footage to scientifically useful information such as the spatial distribution and density of different animal species. Finally, having demonstrated the potential utility of the system, we describe the steps we are taking to adapt the system for work in the field, in particular systematic monitoring of endangered species at National Parks around the world.},
	urldate = {2017-01-24},
	journal = {arXiv:1701.01611 [astro-ph]},
	author = {Longmore, S. N. and Collins, R. P. and Pfeifer, S. and Fox, S. E. and Mulero-Pazmany, M. and Bezombes, F. and Goodwind, A. and Ovelar, M. de Juan and Knapen, J. H. and Wich, S. A.},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.01611},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	annote = {Comment: 16 pages, 6 figures, accepted to International Journal of Remote Sensing},
	file = {arXiv.org Snapshot:/Users/kirk/Zotero/storage/TUHKVAJZ/1701.html:text/html;Longmore et al-2017-Adapting astronomical source detection software to help detect animals in.pdf:/Users/kirk/Zotero/storage/VFVG7UNC/Longmore et al-2017-Adapting astronomical source detection software to help detect animals in.pdf:application/pdf;Longmore et al. - 2017 - Adapting astronomical source detection software to.pdf:/Users/kirk/Zotero/storage/B9Q7RQGC/Longmore et al. - 2017 - Adapting astronomical source detection software to.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/FZZK2JMM/1701.html:text/html},
}

@article{guilford_migration_2009,
	title = {Migration and stopover in a small pelagic seabird, the {Manx} shearwater {Puffinus} puffinus: insights from machine learning},
	shorttitle = {Migration and stopover in a small pelagic seabird, the {Manx} shearwater {Puffinus} puffinus},
	journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	author = {Guilford, T. and Meade, J. and Willis, J. and Phillips, Richard A. and Boyle, D. and Roberts, S. and Collett, M. and Freeman, R. and Perrins, C. M.},
	year = {2009},
	pages = {rspb--2008},
	file = {Fulltext:/Users/kirk/Zotero/storage/R8WTHTUJ/PMC2660961.html:text/html;Snapshot:/Users/kirk/Zotero/storage/DUJU9QJG/rspb.2008.html:text/html},
}

@article{rosa_classification_2016,
	title = {Classification success of six machine learning algorithms in radar ornithology},
	volume = {158},
	number = {1},
	journal = {Ibis},
	author = {Rosa, D. and Isabel, M. and Marques, Ana Teresa and Palminha, Gustavo and Costa, Hugo and Mascarenhas, Miguel and Fonseca, Carlos and Bernardino, Joana},
	year = {2016},
	pages = {28--42},
	file = {Rosa et al-2016-Classification success of six machine learning algorithms in radar ornithology.pdf:/Users/kirk/Zotero/storage/AADT5QVC/Rosa et al-2016-Classification success of six machine learning algorithms in radar ornithology.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/3FYUQMXK/Rosa et al. - 2016 - Classification success of six machine learning alg:},
}

@inproceedings{barry_identifying_2016,
	title = {Identifying biodiversity using citizen science and computer vision: {Introducing} {Visipedia}},
	shorttitle = {Identifying biodiversity using citizen science and computer vision},
	booktitle = {{TDWG} 2016 {ANNUAL} {CONFERENCE}},
	author = {Barry, Jessie},
	year = {2016},
	file = {Snapshot:/Users/kirk/Zotero/storage/WL7QATJN/0.html:text/html},
}

@article{he_visual_2016,
	title = {Visual {Informatics} {Tools} for {Supporting} {Large}-{Scale} {Collaborative} {Wildlife} {Monitoring} with {Citizen} {Scientists}},
	volume = {16},
	issn = {1531-636X},
	doi = {10.1109/MCAS.2015.2510200},
	abstract = {Collaborative wildlife monitoring and tracking at large scales will help us understand the complex dynamics of wildlife systems, evaluate the impact of human actions and environmental changes on wildlife species, and answer many important ecological and evolutionary research questions. To support collaborative wildlife monitoring and research, we need to develop integrated camera-sensor networking systems, deploy them at large scales, and develop advanced computational and informatics tools to analyze and manage the massive wildlife monitoring data. In this paper, we will cover various aspects of the design of such systems, including (1) long-lived integrated camera-sensor system design, (2) image processing and computer vision algorithms for animal detection, segmentation, tracking, species classification, and biometric feature extraction, (3) cloud-based data management, (4) crowd-sourcing based image annotation with citizen scientists, and (5) applications to wildlife and ecological research.},
	number = {1},
	journal = {IEEE Circuits and Systems Magazine},
	author = {He, Z. and Kays, R. and Zhang, Z. and Ning, G. and Huang, C. and Han, T. X. and Millspaugh, J. and Forrester, T. and McShea, W.},
	year = {2016},
	keywords = {ecology, Monitoring, Wildlife, Computer vision, Image processing, crowdsourcing, animal detection, animal tracking, biology computing, biometric feature extraction, Biometrics, cameras, citizen scientists, cloud computing, cloud-based data management, Collaboration, computer vision, computer vision algorithm, feature extraction, Feature extraction, image annotation, image processing algorithm, image segmentation, Informatics, integrated camera-sensor networking system, large-scale collaborative wildlife monitoring, long-lived integrated camera-sensor system design, massive wildlife monitoring data, object tracking, species classification, System analysis and design, visual informatics tool, Visualization, zoology},
	pages = {73--86},
	file = {He et al-2016-Visual Informatics Tools for Supporting Large-Scale Collaborative Wildlife.pdf:/Users/kirk/Zotero/storage/8L97S66S/He et al-2016-Visual Informatics Tools for Supporting Large-Scale Collaborative Wildlife.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/kirk/Zotero/storage/TZ4TG7DI/7404334.html:text/html},
}

@article{hodgson_unmanned_2017,
	title = {Unmanned aerial vehicles for surveying marine fauna: assessing detection probability},
	volume = {27},
	shorttitle = {Unmanned aerial vehicles for surveying marine fauna},
	number = {4},
	journal = {Ecological Applications},
	author = {Hodgson, Amanda and Peel, David and Kelly, Natalie},
	year = {2017},
	pages = {1253--1267},
	file = {Fulltext:/Users/kirk/Zotero/storage/Y9FXH5PF/full.html:text/html;Snapshot:/Users/kirk/Zotero/storage/PD8KD9QJ/Hodgson et al. - 2017 - Unmanned aerial vehicles for surveying marine faun:},
}

@article{seymour_automated_2017,
	title = {Automated detection and enumeration of marine wildlife using unmanned aircraft systems ({UAS}) and thermal imagery},
	volume = {7},
	journal = {Scientific reports},
	author = {Seymour, A. C. and Dale, J. and Hammill, M. and Halpin, P. N. and Johnston, D. W.},
	year = {2017},
	pages = {45127},
	file = {Fulltext:/Users/kirk/Zotero/storage/W84KYEFT/srep45127.html:text/html;Snapshot:/Users/kirk/Zotero/storage/552DMAP3/srep45127.html:text/html},
}

@article{chretien_wildlife_2015,
	title = {Wildlife {Multispecies} {Remote} {Sensing} {Using} {Visible} and {Thermal} {Infrared} {Imagery} {Acquired} from {AN} {Unmanned} {Aerial} {Vehicle} (uav)},
	volume = {40},
	url = {http://search.proquest.com/openview/ecfa31a6b0135d967721c442e039554b/1?pq-origsite=gscholar&cbl=2037674},
	number = {1},
	urldate = {2016-06-13},
	journal = {The International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Chrétien, L. P. and Théau, J. and Ménard, P.},
	year = {2015},
	pages = {241},
	file = {Chrétien et al_2015_Wildlife Multispecies Remote Sensing Using Visible and Thermal Infrared Imagery.pdf:/Users/kirk/Zotero/storage/6RV5G3W2/Chrétien et al_2015_Wildlife Multispecies Remote Sensing Using Visible and Thermal Infrared Imagery.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/UEZVS37J/1.html:text/html},
}

@article{gremillet_robots_2012,
	title = {Robots in ecology: welcome to the machine},
	volume = {2},
	shorttitle = {Robots in ecology},
	number = {2},
	journal = {Open Journal of Ecology},
	author = {Grémillet, D. and Puech, W. and Garçon, V. and Boulinier, T. and Le Maho, Y.},
	year = {2012},
	note = {00003},
	keywords = {\_tablet\_modified},
	pages = {49--57},
	file = {Grémillet et al_ 2012_ Robots in ecology.pdf:/Users/kirk/Zotero/storage/AQH7QIQF/Grémillet et al_ 2012_ Robots in ecology.pdf:application/pdf},
}

@phdthesis{jones_feasibility_2003,
	title = {The feasibility of using small unmanned aerial vehicles for wildlife research},
	url = {http://purl.fcla.edu/fcla/etd/UFE0002620?keepThis=true&TB_iframe=true},
	urldate = {2014-01-28},
	school = {University of Florida},
	author = {Jones, George Pierce},
	year = {2003},
	note = {00012},
	file = {JONES IV_ 2003_ The feasibility of using small unmanned aerial vehicles for wildlife research.pdf:/Users/kirk/Zotero/storage/QEIN848A/JONES IV_ 2003_ The feasibility of using small unmanned aerial vehicles for wildlife research.pdf:application/pdf},
}

@article{focardi_comparative_2001,
	title = {Comparative {Evaluation} of {Thermal} {Infrared} {Imaging} and {Spotlighting} to {Survey} {Wildlife}},
	volume = {29},
	issn = {00917648},
	url = {http://www.jstor.org/stable/3783989},
	number = {1},
	urldate = {2010-02-26},
	journal = {Wildlife Society Bulletin},
	author = {Focardi, Stefano and Marinis, Anna M. De and Rizzotto, Maurizio and Pucci, Alessandra},
	year = {2001},
	note = {00051 
ArticleType: primary\_article / Full publication date: Spring, 2001 / Copyright © 2001 Allen Press},
	pages = {133--139},
}

@article{franke_aerial_2012,
	title = {Aerial ungulate surveys with a combination of infrared and high–resolution natural colour images},
	volume = {35},
	url = {http://www.raco.cat/index.php/ABC/article/view/259214},
	number = {2},
	urldate = {2014-01-28},
	journal = {Animal Biodiversity and Conservation},
	author = {Franke, U. and Goll, B. and Hohmann, U. and Heurich, M.},
	year = {2012},
	note = {00001},
	pages = {285--293},
	file = {Franke et al_ 2012_ Aerial ungulate surveys with a combination of infrared and high–resolution.pdf:/Users/kirk/Zotero/storage/S5TTKI7N/Franke et al_ 2012_ Aerial ungulate surveys with a combination of infrared and high–resolution.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/DXSUB856/259214.html:text/html},
}

@article{delplanque_surveying_2023,
	title = {Surveying wildlife and livestock in {Uganda} with aerial cameras: {Deep} {Learning} reduces the workload of human interpretation by over 70\%},
	volume = {11},
	issn = {2296-701X},
	shorttitle = {Surveying wildlife and livestock in {Uganda} with aerial cameras},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2023.1270857},
	abstract = {As the need to accurately monitor key-species populations grows amid increasing pressures on global biodiversity, the counting of large mammals in savannas has traditionally relied on the Systematic-Reconnaissance-Flight (SRF) technique using light aircrafts and human observers. However, this method has limitations, including non-systematic human errors. In recent years, the Oblique-Camera-Count (OCC) approach developed in East Africa has utilized cameras to capture high-resolution imagery replicating aircraft observers’ oblique view. Whilst demonstrating that human observers have missed many animals, OCC relies on labor-intensive human interpretation of thousands of images. This study explores the potential of Deep Learning (DL) to reduce the interpretation workload associated with OCC surveys. Using oblique aerial imagery of 2.1 hectares footprint collected during an SRF-OCC survey of Queen Elizabeth Protected Area in Uganda, a DL model (HerdNet) was trained and evaluated to detect and count 12 wildlife and livestock mammal species. The model’s performance was assessed both at the animal instance-based and image-based levels, achieving accurate detection performance (F1 score of 85\%) in positive images (i.e. containing animals) and reducing manual interpretation workload by 74\% on a realistic dataset showing less than 10\% of positive images. However, it struggled to differentiate visually related species and overestimated animal counts due to false positives generated by landscape items resembling animals. These challenges may be addressed through improved training and verification processes. The results highlight DL’s potential to semi-automate processing of aerial survey wildlife imagery, reducing manual interpretation burden. By incorporating DL models into existing counting standards, future surveys may increase sampling efforts, improve accuracy, and enhance aerial survey safety.},
	urldate = {2024-02-17},
	journal = {Frontiers in Ecology and Evolution},
	author = {Delplanque, Alexandre and Lamprey, Richard and Foucher, Samuel and Théau, Jérôme and Lejeune, Philippe},
	year = {2023},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/IZY8N8XH/Delplanque et al. - 2023 - Surveying wildlife and livestock in Uganda with aerial cameras Deep Learning reduces the workload o.pdf:application/pdf},
}

@inproceedings{delplanque_counting_2022,
	title = {Counting {African} {Mammal} {Herds} in {Aerial} {Imagery} {Using} {Deep} {Learning}: {Are} {Anchor}-{Based} {Algorithms} the {Most} {Suitable}?},
	shorttitle = {Counting {African} {Mammal} {Herds} in {Aerial} {Imagery} {Using} {Deep} {Learning}},
	url = {https://orbi.uliege.be/handle/2268/293320},
	abstract = {Monitoring wildlife and livestock in protected areas is essential to reach natural ecosystem conservation goals. In large open areas, this is often carried out by direct counting from observers in manned aircrafts flying at low altitude. However, there are several biases associated with this method, resulting in a low accuracy of large groups counts. Unmanned Aerial Vehicles (UAVs) have experienced a significant growth in recent years and seem to be relatively well-suited systems for photographing animals. While UAVs allow for more accurate herd counts than traditional methods, identification and counting are usually indirectly done during a manual time-consuming photo-interpretation process. For several years, machine learning and deep learning techniques have been developed and now show encouraging results for automatic animal detection. Some of them use Convolutional Neural Networks (CNNs) through anchor-based object detectors. These algorithms automatically extract relevant features from images, produce thousands of anchors all over the image and eventually decide which ones actually contain an object. Counting and classification are then achieved by summing and classifying all the selected bounding boxes. While this approach worked well for isolated mammals or sparse herds, it showed limits in close-by individuals by generating too many false positives, resulting in overestimated counts in dense herds. This raises the question: are anchor-based algorithms the most suitable for counting large mammals in aerial imagery? In an attempt to answer this, we built a simple one stage point-based object detector on a dataset acquired over various African landscapes which contains six large mammal species: buffalo (Syncerus caffer), elephant (Loxodonta africana), kob (Kobus kob), topi (Damaliscus lunatus jimela), warthog (Phacochoerus africanus) and waterbuck (Kobus ellipsiprymnus). An adapted version of the  CNN DLA-34 was trained on points only (center of the original bounding boxes), splat onto a Focal Inverse Distance Transform (FIDT) map regressed in a pixel-wise manner using the focal loss. During inference, local maxima were extracted from the predicted map to obtain the animals location. Binary model’s performances were then compared to those of the state-of-the-art model, Libra-RCNN. Although our model detected 5\% fewer animals compared to the baseline, its precision doubled from 37\% to 70\%, reducing the number of false positives by one third without using any hard negative mining method. The results obtained also showed a clear increase in precision in close-by individuals areas, letting it appear that a point-based approach seems to be better adapted for animal detection in herds than anchor-based ones. Future work will apply this approach on other animal datasets with different acquisition conditions (e.g. oblique viewing angle, coarser resolution, denser herds) to evaluate its range of use.},
	language = {Anglais},
	urldate = {2024-02-17},
	author = {Delplanque, Alexandre and Foucher, Samuel and Lejeune, Philippe and Théau, Jérôme},
	month = jul,
	year = {2022},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/NYF6JCCR/Delplanque et al. - 2022 - Counting African Mammal Herds in Aerial Imagery Using Deep Learning Are Anchor-Based Algorithms the.pdf:application/pdf},
}

@article{delplanque_crowd_2023,
	title = {From crowd to herd counting: {How} to precisely detect and count {African} mammals using aerial imagery and deep learning?},
	volume = {197},
	issn = {0924-2716},
	shorttitle = {From crowd to herd counting},
	url = {https://www.sciencedirect.com/science/article/pii/S092427162300031X},
	doi = {10.1016/j.isprsjprs.2023.01.025},
	abstract = {Rapid growth of human populations in sub-Saharan Africa has led to a simultaneous increase in the number of livestock, often leading to conflicts of use with wildlife in protected areas. To minimize these conflicts, and to meet both communities’ and conservation goals, it is therefore essential to monitor livestock density and their land use. This is usually done by conducting aerial surveys during which aerial images are taken for later counting. Although this approach appears to reduce counting bias, the manual processing of images is time-consuming. The use of dense convolutional neural networks (CNNs) has emerged as a very promising avenue for processing such datasets. However, typical CNN architectures have detection limits for dense herds and close-by animals. To tackle this problem, this study introduces a new point-based CNN architecture, HerdNet, inspired by crowd counting. It was optimized on challenging oblique aerial images containing herds of camels (Camelus dromedarius), donkeys (Equus asinus), sheep (Ovis aries) and goats (Capra hircus), acquired over heterogeneous arid landscapes of the Ennedi reserve (Chad). This approach was compared to an anchor-based architecture, Faster-RCNN, and a density-based, adapted version of DLA-34 that is typically used in crowd counting. HerdNet achieved a global F1 score of 73.6 \% on 24 megapixels images, with a root mean square error of 9.8 animals and at a processing speed of 3.6 s, outperforming the two baselines in terms of localization, counting and speed. It showed better proximity-invariant precision while maintaining equivalent recall to that of Faster-RCNN, thus demonstrating that it is the most suitable approach for detecting and counting large mammals at close range. The only limitation of HerdNet was the slightly weaker identification of species, with an average confusion rate approximately 4 \% higher than that of Faster-RCNN. This study provides a new CNN architecture that could be used to develop an automatic livestock counting tool in aerial imagery. The reduced image analysis time could motivate more frequent flights, thus allowing a much finer monitoring of livestock and their land use.},
	urldate = {2024-02-17},
	journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
	author = {Delplanque, Alexandre and Foucher, Samuel and Théau, Jérôme and Bussière, Elsa and Vermeulen, Cédric and Lejeune, Philippe},
	month = mar,
	year = {2023},
	keywords = {Protected area, Livestock, Deep learning, Aerial survey, Convolutional neural networks, Herd},
	pages = {167--180},
	file = {ScienceDirect Full Text PDF:/Users/kirk/Zotero/storage/3XENEJGH/Delplanque et al. - 2023 - From crowd to herd counting How to precisely detect and count African mammals using aerial imagery .pdf:application/pdf;ScienceDirect Snapshot:/Users/kirk/Zotero/storage/JXCXX2A9/S092427162300031X.html:text/html},
}

@article{tuia_perspectives_2022,
	title = {Perspectives in machine learning for wildlife conservation},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-27980-y},
	doi = {10.1038/s41467-022-27980-y},
	abstract = {Inexpensive and accessible sensors are accelerating data acquisition in animal ecology. These technologies hold great potential for large-scale ecological understanding, but are limited by current processing approaches which inefficiently distill data into relevant information. We argue that animal ecologists can capitalize on large datasets generated by modern sensors by combining machine learning approaches with domain knowledge. Incorporating machine learning into ecological workflows could improve inputs for ecological models and lead to integrated hybrid modeling tools. This approach will require close interdisciplinary collaboration to ensure the quality of novel approaches and train a new generation of data scientists in ecology and conservation.},
	language = {en},
	number = {1},
	urldate = {2024-03-03},
	journal = {Nature Communications},
	author = {Tuia, Devis and Kellenberger, Benjamin and Beery, Sara and Costelloe, Blair R. and Zuffi, Silvia and Risse, Benjamin and Mathis, Alexander and Mathis, Mackenzie W. and van Langevelde, Frank and Burghardt, Tilo and Kays, Roland and Klinck, Holger and Wikelski, Martin and Couzin, Iain D. and van Horn, Grant and Crofoot, Margaret C. and Stewart, Charles V. and Berger-Wolf, Tanya},
	month = feb,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Conservation biology, Computer science},
	pages = {792},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/GPS2MSHE/Tuia et al. - 2022 - Perspectives in machine learning for wildlife conservation.pdf:application/pdf},
}

@article{xu_review_2024,
	title = {A review of deep learning techniques for detecting animals in aerial and satellite images},
	volume = {128},
	issn = {1569-8432},
	url = {https://www.sciencedirect.com/science/article/pii/S1569843224000864},
	doi = {10.1016/j.jag.2024.103732},
	abstract = {Deep learning is an effective machine learning method that in recent years has been successfully applied to detect and monitor species population in remotely sensed data. This study aims to provide a systematic literature review of current applications of deep learning methods for animal detection in aerial and satellite images. We categorized methods in collated publications into image level, point level, bounding-box level, instance segmentation level, and specific information level. The statistical results show that YOLO, Faster R-CNN, U-Net and ResNet are the most used neural network structures. The main challenges associated with the use of these deep learning methods are imbalanced datasets, small samples, small objects, image annotation methods, image background, animal counting, model accuracy assessment, and uncertainty estimation. We explored possible solutions include the selection of sample annotation methods, optimizing positive or negative samples, using weakly and self-supervised learning methods, selecting or developing more suitable network structures. Future research trends we identified are video-based detection, very high-resolution satellite image-based detection, multiple species detection, new annotation methods, and the development of specialized network structures and large foundation models. We discussed existing research attempts as well as personal perspectives on these possible solutions and future trends.},
	urldate = {2024-03-03},
	journal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Xu, Zeyu and Wang, Tiejun and Skidmore, Andrew K. and Lamprey, Richard},
	month = apr,
	year = {2024},
	keywords = {Biodiversity, Remote sensing, Wildlife, Livestock, Artificial intelligence, Object detection},
	pages = {103732},
	file = {ScienceDirect Snapshot:/Users/kirk/Zotero/storage/J47R53GD/S1569843224000864.html:text/html},
}

@inproceedings{naude_aerial_2019,
	title = {The {Aerial} {Elephant} {Dataset}: {A} {New} {Public} {Benchmark} for {Aerial} {Object} {Detection}.},
	shorttitle = {The {Aerial} {Elephant} {Dataset}},
	url = {https://openaccess.thecvf.com/content_CVPRW_2019/html/DOAI/Naude_The_Aerial_Elephant_Dataset_A_New_Public_Benchmark_for_Aerial_CVPRW_2019_paper.html},
	urldate = {2024-03-03},
	author = {Naude, Johannes and Joubert, Deon},
	year = {2019},
	pages = {48--55},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/BH45LH2F/Naude and Joubert - 2019 - The Aerial Elephant Dataset A New Public Benchmark for Aerial Object Detection..pdf:application/pdf},
}

@article{zhang_ce-retinanet_2023,
	title = {{CE}-{RetinaNet}: {A} {Channel} {Enhancement} {Method} for {Infrared} {Wildlife} {Detection} in {UAV} {Images}},
	volume = {61},
	issn = {1558-0644},
	shorttitle = {{CE}-{RetinaNet}},
	url = {https://ieeexplore.ieee.org/document/10196493},
	doi = {10.1109/TGRS.2023.3299651},
	abstract = {Thermal infrared (TIR) technology is crucial for wildlife detection in unmanned aerial vehicles (UAVs), allowing executives to explore and detect at night. However, the images captured by TIR cameras are unavoidably affected by various unexpected challenges such as image jitter, wildlife overlap, and fog, which may drastically decrease wildlife detection ability. To overcome these challenges, we propose a high-accuracy infrared object detection method called channel enhancement RetinaNet (CE-RetinaNet). First, a new channel enhancement (CE) module is proposed to strengthen the feature extraction of infrared images. Then, a new batch-norm stochastic channel attention (BSCA) module is proposed to filter occlusion-caused anomalous activations and focus on the pixel in the same position across channels. Next, a path augmentation (PA) operation is added after the feature pyramid network (FPN) to improve the localization capability at the entire feature level. Finally, we modified the output strategy of the classification and regression subnets. Additionally, we built a TIR wildlife detection dataset called the infrared salient object detection (ISOD) comprising 2534 images, which is accessible at https://doi.org/10.5281/zenodo.7445307. We conduct extensive experiments on both public and ISOD datasets, and the experimental results reveal that CE-RetinaNet obtains higher average precision (AP) (e.g., 11.3\% more) and Recall (e.g., 11.6\% more) compared to other state-of-the-art object detectors.},
	urldate = {2024-03-03},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Zhang, Yongle and Cai, Zhanchuan},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Computational modeling, Remote sensing, Wildlife, Object detection, Feature extraction, Autonomous aerial vehicles, Jitter, Semantics, thermal infrared (TIR) image, unmanned aerial vehicles (UAVs), wildlife detection},
	pages = {1--12},
	file = {IEEE Xplore Abstract Record:/Users/kirk/Zotero/storage/LHNHIMHE/10196493.html:text/html;IEEE Xplore Full Text PDF:/Users/kirk/Zotero/storage/H9HJBH2H/Zhang and Cai - 2023 - CE-RetinaNet A Channel Enhancement Method for Infrared Wildlife Detection in UAV Images.pdf:application/pdf},
}

@article{doll_comparison_nodate,
	title = {Comparison of {Object} {Detection} {Algorithms} for {Livestock} {Monitoring} of {Sheep} in {UAV} images},
	abstract = {This paper presents the EU funded project SPADE, a European initiative that aims to create an Intelligent Ecosystem utilizing unmanned aerial vehicles (UAVs) for delivering sustainable digital services to various end users in sectors like agriculture, forestry, and livestock. The project’s main goal is to cater to multiple purposes and benefit a wide range of stakeholders. In this paper we specifically concentrate on the livestock use-case and explore how state-of-the-art computer vision algorithms for object detection, tracking, and landscape classification, deployed on edge devices in drones, can offer researchers, conservationists, and farmers a non-intrusive, cost-effective, and efficient method for monitoring livestock increasing animal welfare, and optimize livestock management. We present initial findings by comparing the performance of different state-of-the-art object detectors on publicly available UAV images of sheep. The key performance metrics used are average precision, mean average precision and mean average recall. These findings should enable a better pre-selection of potential object detectors for the presented edge device use case.},
	language = {en},
	author = {Doll, Oliver and Loos, Alexander},
	file = {Doll and Loos - Comparison of Object Detection Algorithms for Livestock Monitoring of Sheep in UAV images.pdf:/Users/kirk/Zotero/storage/6BPHXDHF/Doll and Loos - Comparison of Object Detection Algorithms for Livestock Monitoring of Sheep in UAV images.pdf:application/pdf},
}

@article{eikelboom_improving_2019,
	title = {Improving the precision and accuracy of animal population estimates with aerial image object detection},
	volume = {10},
	copyright = {© 2019 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13277},
	doi = {10.1111/2041-210X.13277},
	abstract = {Animal population sizes are often estimated using aerial sample counts by human observers, both for wildlife and livestock. The associated methods of counting remained more or less the same since the 1970s, but suffer from low precision and low accuracy of population estimates. Aerial counts using cost-efficient Unmanned Aerial Vehicles or microlight aircrafts with cameras and an automated animal detection algorithm can potentially improve this precision and accuracy. Therefore, we evaluated the performance of the multi-class convolutional neural network RetinaNet in detecting elephants, giraffes and zebras in aerial images from two Kenyan animal counts. The algorithm detected 95\% of the number of elephants, 91\% of giraffes and 90\% of zebras that were found by four layers of human annotation, of which it correctly detected an extra 2.8\% of elephants, 3.8\% giraffes and 4.0\% zebras that were missed by all humans, while detecting only 1.6 to 5.0 false positives per true positive. Furthermore, the animal detections by the algorithm were less sensitive to the sighting distance than humans were. With such a high recall and precision, we posit it is feasible to replace manual aerial animal count methods (from images and/or directly) by only the manual identification of image bounding boxes selected by the algorithm and then use a correction factor equal to the inverse of the undercounting bias in the calculation of the population estimates. This correction factor causes the standard error of the population estimate to increase slightly compared to a manual method, but this increase can be compensated for when the sampling effort would increase by 23\%. However, an increase in sampling effort of 160\% to 1,050\% can be attained with the same expenses for equipment and personnel using our proposed semi-automatic method compared to a manual method. Therefore, we conclude that our proposed aerial count method will improve the accuracy of population estimates and will decrease the standard error of population estimates by 31\% to 67\%. Most importantly, this animal detection algorithm has the potential to outperform humans in detecting animals from the air when supplied with images taken at a fixed rate.},
	language = {en},
	number = {11},
	urldate = {2024-03-04},
	journal = {Methods in Ecology and Evolution},
	author = {Eikelboom, Jasper A. J. and Wind, Johan and van de Ven, Eline and Kenana, Lekishon M. and Schroder, Bradley and de Knegt, Henrik J. and van Langevelde, Frank and Prins, Herbert H. T.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13277},
	keywords = {savanna, drones, wildlife survey, convolutional neural network, computer vision, deep machine learning, game census, image recognition},
	pages = {1875--1887},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/58I9MG2N/Eikelboom et al. - 2019 - Improving the precision and accuracy of animal population estimates with aerial image object detecti.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/9QZP3E7X/2041-210X.html:text/html},
}

@article{torney_comparison_2019,
	title = {A comparison of deep learning and citizen science techniques for counting wildlife in aerial survey images},
	volume = {10},
	copyright = {© 2019 The Authors. Methods in Ecology and Evolution © 2019 British Ecological Society},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13165},
	doi = {10.1111/2041-210X.13165},
	abstract = {Fast and accurate estimates of wildlife abundance are an essential component of efforts to conserve ecosystems in the face of rapid environmental change. A widely used method for estimating species abundance involves flying aerial transects, taking photographs, counting animals within the images and then inferring total population size based on a statistical estimate of species density in the region. The intermediate task of manually counting the aerial images is highly labour intensive and is often the limiting step in making a population estimate. Here, we assess the use of two novel approaches to perform this task by deploying both citizen scientists and deep learning to count aerial images of the 2015 survey of wildebeest (Connochaetes taurinus) in Serengeti National Park, Tanzania. Through the use of the online platform Zooniverse, we collected multiple non-expert counts by citizen scientists and used three different aggregation methods to obtain a single count for the survey images. We also counted the images by developing a bespoke deep learning method via the use of a convolutional neural network. The results of both approaches were then compared. After filtering of the citizen science counts, both approaches provided highly accurate total estimates. The deep learning method was far faster and appears to be a more reliable and predictable approach; however, we note that citizen science volunteers played an important role when creating training data for the algorithm. Notably, our results show that accurate, species-specific, automated counting of aerial wildlife images is now possible.},
	language = {en},
	number = {6},
	urldate = {2024-03-04},
	journal = {Methods in Ecology and Evolution},
	author = {Torney, Colin J. and Lloyd-Jones, David J. and Chevallier, Mark and Moyer, David C. and Maliti, Honori T. and Mwita, Machoke and Kohi, Edward M. and Hopcraft, Grant C.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13165},
	keywords = {conservation, monitoring, citizen science, population ecology, deep learning, surveys},
	pages = {779--787},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/PXTZEPAT/Torney et al. - 2019 - A comparison of deep learning and citizen science techniques for counting wildlife in aerial survey.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/BSG3GCFC/2041-210X.html:text/html},
}

@article{kellenberger_aide_2020,
	title = {{AIDE}: {Accelerating} image-based ecological surveys with interactive machine learning},
	volume = {11},
	copyright = {© 2020 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society},
	issn = {2041-210X},
	shorttitle = {{AIDE}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13489},
	doi = {10.1111/2041-210X.13489},
	abstract = {Ecological surveys increasingly rely on large-scale image datasets, typically terabytes of imagery for a single survey. The ability to collect this volume of data allows surveys of unprecedented scale, at the cost of expansive volumes of photo-interpretation labour. We present Annotation Interface for Data-driven Ecology (AIDE), an open-source web framework designed to alleviate the task of image annotation for ecological surveys. AIDE employs an easy-to-use and customisable labelling interface that supports multiple users, database storage and scalability to the cloud and/or multiple machines. Moreover, AIDE closely integrates users and machine learning models into a feedback loop, where user-provided annotations are employed to re-train the model, and the latter is applied over unlabelled images to e.g. identify wildlife. These predictions are then presented to the users in optimised order, according to a customisable active learning criterion. AIDE has a number of deep learning models built-in, but also accepts custom model implementations. Annotation Interface for Data-driven Ecology has the potential to greatly accelerate annotation tasks for a wide range of researches employing image data. AIDE is open-source and can be downloaded for free at https://github.com/microsoft/aerial\_wildlife\_detection.},
	language = {en},
	number = {12},
	urldate = {2024-06-11},
	journal = {Methods in Ecology and Evolution},
	author = {Kellenberger, Benjamin and Tuia, Devis and Morris, Dan},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13489},
	keywords = {conservation, monitoring (population ecology), population ecology, surveys, applied ecology, statistics},
	pages = {1716--1727},
	file = {Full Text:/Users/kirk/Zotero/storage/HLHAJAB6/Kellenberger et al. - 2020 - AIDE Accelerating image-based ecological surveys with interactive machine learning.pdf:application/pdf;Snapshot:/Users/kirk/Zotero/storage/G22V4Y4S/2041-210X.html:text/html},
}

@article{delplanque_will_2024,
	title = {Will artificial intelligence revolutionize aerial surveys? {A} first large-scale semi-automated survey of {African} wildlife using oblique imagery and deep learning},
	volume = {82},
	issn = {1574-9541},
	shorttitle = {Will artificial intelligence revolutionize aerial surveys?},
	url = {https://www.sciencedirect.com/science/article/pii/S1574954124002218},
	doi = {10.1016/j.ecoinf.2024.102679},
	abstract = {Large African mammal populations are traditionally estimated using the systematic reconnaissance flights (SRF) with rear-seat observers (RSOs). The oblique-camera-count (OCC) approach, utilizing digital cameras on aircraft sides, proved to provide more reliable population estimates but incurs high manual processing costs. Addressing the urgent need for efficiency, the research explores whether a semi-automated deep learning (SADL) model coupled with OCC improves wildlife population estimates compared to the SRF-RSO method. The study area was the Comoé National Park, in Ivory Coast, spanning 11,488 km2 of savannas and open forests. It was surveyed following both SRF-RSO standards and OCC method. Key species included the elephant, western hartebeest, roan antelope, buffalo, kob, waterbuck and warthog. The deep learning model HerdNet, priorly pre-trained on images from Uganda, was incorporated in the SADL pipeline to process the 190,686 images. It involved three human verification steps to ensure quality of detections and to avoid overestimating counts. The entire pipeline aims to balance efficiency and human effort in wildlife population estimation. RSO and SADL-OCC approaches were compared using the Jolly II analysis and a verification of 200 random RSO observations. Jolly II analysis revealed SADL-OCC estimates significantly higher for small-sized species (kob, warthog) and comparable for other key species. Counting differences were mainly attributed to vegetation obstruction, RSO observations not found in the images, and suspected RSO counting errors. Human effort in the SADL-OCC approach totaled 111 h, representing a significant time savings compared to a fully manual interpretation. Introducing the SADL approach for aerial surveys in Comoé National Park enabled us to address the OCC's time-intensive image interpretation. Achieving a significant reduction in human workload, our method provided population estimates comparable to or better than SRF-RSO counts. Vegetation obstruction was a key factor explaining differences, highlighting the OCC method's limitation in vegetated areas. Method comparisons emphasized SADL-OCC's advantages in spotting isolated, small and static animals, reducing count variance between sample units. Despite limitations, the SADL-OCC approach offers transformative potential, suggesting a shift towards DL-assisted aerial surveys for increased efficiency and affordability, especially using microlight aircraft and drones in future wildlife monitoring initiatives.},
	urldate = {2024-06-22},
	journal = {Ecological Informatics},
	author = {Delplanque, Alexandre and Linchant, Julie and Vincke, Xavier and Lamprey, Richard and Théau, Jérôme and Vermeulen, Cédric and Foucher, Samuel and Ouattara, Amara and Kouadio, Roger and Lejeune, Philippe},
	month = sep,
	year = {2024},
	keywords = {African savanna, Deep learning, Biodiversity monitoring, Aerial surveys, Conservation technology, Wildlife population estimation},
	pages = {102679},
	file = {ScienceDirect Full Text PDF:/Users/kirk/Zotero/storage/EQU887H6/Delplanque et al. - 2024 - Will artificial intelligence revolutionize aerial surveys A first large-scale semi-automated survey.pdf:application/pdf;ScienceDirect Snapshot:/Users/kirk/Zotero/storage/K6BMAJNX/S1574954124002218.html:text/html},
}

@inproceedings{kumar_wildlifemapper_2024,
	title = {{WildlifeMapper}: {Aerial} {Image} {Analysis} for {Multi}-{Species} {Detection} and {Identification}},
	shorttitle = {{WildlifeMapper}},
	url = {https://openaccess.thecvf.com/content/CVPR2024/html/Kumar_WildlifeMapper_Aerial_Image_Analysis_for_Multi-Species_Detection_and_Identification_CVPR_2024_paper.html},
	language = {en},
	urldate = {2024-06-22},
	author = {Kumar, Satish and Zhang, Bowen and Gudavalli, Chandrakanth and Levenson, Connor and Hughey, Lacey and Stabach, Jared A. and Amoke, Irene and Ojwang, Gordon and Mukeka, Joseph and Mwiu, Stephen and Ogutu, Joseph and Frederick, Howard and Manjunath, B. S.},
	year = {2024},
	pages = {12594--12604},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/MAFCS6TG/Kumar et al. - 2024 - WildlifeMapper Aerial Image Analysis for Multi-Species Detection and Identification.pdf:application/pdf},
}

@misc{augustine_towards_2023,
	title = {Towards estimating marine wildlife abundance using aerial surveys and deep learning with hierarchical classifications subject to error},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2023.02.20.529272v1},
	doi = {10.1101/2023.02.20.529272},
	abstract = {Aerial count surveys of wildlife populations are a prominent monitoring method for many wildlife species. Traditionally, these surveys utilize human observers to detect, count, and classify observations to species. However, given recent technological advances, many research groups are exploring the combined use of remote sensing and deep learning methods to replace human observers in order to improve data quality and reproducibility, reduce disturbance to wildlife, and increase aircrew safety. Given that deep learning detection and classification are not perfect and that statistical inference from ecological models is generally very sensitive to misclassification, we require study designs and statistical models to accommodate these observation errors.
As part of an ongoing effort by the U.S. Fish and Wildlife Service, Bureau of Ocean Energy Management, and U.S. Geological Survey to survey marine birds and other marine wildlife using digital aerial imagery and deep learning object detection and classification, we developed a general hierarchical model for estimating species-specific abundance that accommodates object-level errors in classification. We consider hierarchical deep learning classification at multiple taxonomic levels subject to misclassification, hierarchically-structured human validation data subject to partial and erroneous misclassification, and an image censoring process leading to preferential sampling. We demonstrate that this model can estimate species-specific abundance and habitat relationships without bias when the assumptions are met, and we discuss the plausibility of these assumptions in practice for this study and others like it.
Finally, we use this model to demonstrate the relevance of the features of the ecological systems under study to the classification task itself. In models that couple the ecological and classification processes into a single, hierarchical model, the true classes are treated as latent variables to be estimated and are informed by both the classification probability parameters and the ecological parameters that determine the expected frequencies of each class at the level the data are being modeled (e.g., site or site by occasion). We show that ignoring the expected frequencies of each class (when they are imbalanced) can cause correction for misclassification to produce biased parameter estimates, but coupling the ecological and classification models allows for the variability in relative class frequency across space and time due to ecological and sampling conditions to be accommodated with spatial or temporal covariates. As a result, bias is removed, classification is more accurate, and uncertainty is propagated between the ecological and classification models. We therefore argue that ability of deep learning classifiers, and classifiers more generally, to produce reliable ecological inference depends, in part, on the ecological system under study.},
	language = {en},
	urldate = {2024-06-26},
	publisher = {bioRxiv},
	author = {Augustine, Ben C. and Koneff, Mark D. and Pickens, Bradley A. and Royle, J. Andrew},
	month = feb,
	year = {2023},
	note = {Pages: 2023.02.20.529272
Section: New Results},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/92BU3LGQ/Augustine et al. - 2023 - Towards estimating marine wildlife abundance using aerial surveys and deep learning with hierarchica.pdf:application/pdf},
}

@article{xu_review_2024-1,
	title = {A review of deep learning techniques for detecting animals in aerial and satellite images},
	volume = {128},
	issn = {1569-8432},
	url = {https://www.sciencedirect.com/science/article/pii/S1569843224000864},
	doi = {10.1016/j.jag.2024.103732},
	abstract = {Deep learning is an effective machine learning method that in recent years has been successfully applied to detect and monitor species population in remotely sensed data. This study aims to provide a systematic literature review of current applications of deep learning methods for animal detection in aerial and satellite images. We categorized methods in collated publications into image level, point level, bounding-box level, instance segmentation level, and specific information level. The statistical results show that YOLO, Faster R-CNN, U-Net and ResNet are the most used neural network structures. The main challenges associated with the use of these deep learning methods are imbalanced datasets, small samples, small objects, image annotation methods, image background, animal counting, model accuracy assessment, and uncertainty estimation. We explored possible solutions include the selection of sample annotation methods, optimizing positive or negative samples, using weakly and self-supervised learning methods, selecting or developing more suitable network structures. Future research trends we identified are video-based detection, very high-resolution satellite image-based detection, multiple species detection, new annotation methods, and the development of specialized network structures and large foundation models. We discussed existing research attempts as well as personal perspectives on these possible solutions and future trends.},
	urldate = {2024-06-28},
	journal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Xu, Zeyu and Wang, Tiejun and Skidmore, Andrew K. and Lamprey, Richard},
	month = apr,
	year = {2024},
	keywords = {Biodiversity, Remote sensing, Wildlife, Livestock, Artificial intelligence, Object detection},
	pages = {103732},
	file = {ScienceDirect Full Text PDF:/Users/kirk/Zotero/storage/QUCDLR93/Xu et al. - 2024 - A review of deep learning techniques for detecting animals in aerial and satellite images.pdf:application/pdf;ScienceDirect Snapshot:/Users/kirk/Zotero/storage/FKKDJZHK/S1569843224000864.html:text/html},
}

@article{lamprey_cameras_2020,
	title = {Cameras replace human observers in multi-species aerial counts in {Murchison} {Falls}, {Uganda}},
	volume = {6},
	copyright = {© 2020 2020 The Authors. Remote Sensing in Ecology and Conservation published by John Wiley \& Sons Ltd on behalf of Zoological Society of London},
	issn = {2056-3485},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.154},
	doi = {10.1002/rse2.154},
	abstract = {Wildlife counts in Africa and elsewhere are often implemented using light aircraft with ‘rear-seat-observer’ (RSO) counting crews. Previous research has indicated that RSOs often fail to detect animals, and that population estimates are therefore biased. We conducted aerial wildlife surveys in Murchison Falls Protected Area, Uganda, in which we replaced RSOs with high-definition ‘oblique camera count’ (OCC) systems. The survey area comprises forests, woodlands and grasslands. Four counts were conducted in 2015–2016 using a systematic-reconnaissance-flight (SRF) strip-transect design. Camera inclination angles, focal lengths, altitude and frame interval were calibrated to provide imaged strips of known sample size on the left and right sides of the aircraft. Using digital cameras, 24 000 high-definition images were acquired for each count, which were visually interpreted by four airphoto interpreters. We used the standard Jolly II SRF analysis to derive population estimates. Our OCC estimates of the antelopes – hartebeest, Uganda kob, waterbuck and oribi – were, respectively, 25\%, 103\%, 97\% and 2100\% higher than in the most recent RSO count conducted in 2014. The OCC surveys doubled the 2014 RSO estimate of 58 000 Uganda kob to over 118 000. Population size estimates of elephants and giraffes did not differ significantly. Although all four OCC buffalo estimates were higher than the RSO estimates – in one count by 60\% – these differences were not significant due to the clumped distribution and high variation in herd sizes, resulting in imprecise estimation by sampling. We conclude that RSO wildlife counts in Murchison have been effective in enumerating elephants and giraffe, but that many smaller species have not been well detected. We emphasize the importance of 60 years of RSO-based surveys across Africa, but suggest that new imaging technologies are embraced to improve accuracy.},
	language = {en},
	number = {4},
	urldate = {2024-06-28},
	journal = {Remote Sensing in Ecology and Conservation},
	author = {Lamprey, Richard and Ochanda, David and Brett, Rob and Tumwesigye, Charles and Douglas-Hamilton, Iain},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rse2.154},
	keywords = {Uganda, bias, population estimate, cameras, Aerial surveys, wildlife counts},
	pages = {529--545},
	file = {Snapshot:/Users/kirk/Zotero/storage/37BHR895/rse2.html:text/html},
}

@article{viegut_detection_2024,
	title = {Detection {Probability} and {Bias} in {Machine}-{Learning}-{Based} {Unoccupied} {Aerial} {System} {Non}-{Breeding} {Waterfowl} {Surveys}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2504-446X},
	url = {https://www.mdpi.com/2504-446X/8/2/54},
	doi = {10.3390/drones8020054},
	abstract = {Unoccupied aerial systems (UASs) may provide cheaper, safer, and more accurate and precise alternatives to traditional waterfowl survey techniques while also reducing disturbance to waterfowl. We evaluated availability and perception bias based on machine-learning-based non-breeding waterfowl count estimates derived from aerial imagery collected using a DJI Mavic Pro 2 on Missouri Department of Conservation intensively managed wetland Conservation Areas. UASs imagery was collected using a proprietary software for automated flight path planning in a back-and-forth transect flight pattern at ground sampling distances (GSDs) of 0.38–2.29 cm/pixel (15–90 m in altitude). The waterfowl in the images were labeled by trained labelers and simultaneously analyzed using a modified YOLONAS image object detection algorithm developed to detect waterfowl in aerial images. We used three generalized linear mixed models with Bernoulli distributions to model availability and perception (correct detection and false-positive) detection probabilities. The variation in waterfowl availability was best explained by the interaction of vegetation cover type, sky condition, and GSD, with more complex and taller vegetation cover types reducing availability at lower GSDs. The probability of the algorithm correctly detecting available birds showed no pattern in terms of vegetation cover type, GSD, or sky condition; however, the probability of the algorithm generating incorrect false-positive detections was best explained by vegetation cover types with features similar in size and shape to the birds. We used a modified Horvitz–Thompson estimator to account for availability and perception biases (including false positives), resulting in a corrected count error of 5.59 percent. Our results indicate that vegetation cover type, sky condition, and GSD influence the availability and detection of waterfowl in UAS surveys; however, using well-trained algorithms may produce accurate counts per image under a variety of conditions.},
	language = {en},
	number = {2},
	urldate = {2024-08-08},
	journal = {Drones},
	author = {Viegut, Reid and Webb, Elisabeth and Raedeke, Andrew and Tang, Zhicheng and Zhang, Yang and Zhai, Zhenduo and Liu, Zhiguang and Wang, Shiqi and Zheng, Jiuyi and Shang, Yi},
	month = feb,
	year = {2024},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {wetland, aerial survey, artificial intelligence, drones, abundance estimation, detection probability, waterfowl},
	pages = {54},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/K9PGQWKA/Viegut et al. - 2024 - Detection Probability and Bias in Machine-Learning-Based Unoccupied Aerial System Non-Breeding Water.pdf:application/pdf},
}

@article{lenzi_artificial_2023,
	title = {Artificial intelligence for automated detection of large mammals creates path to upscale drone surveys},
	volume = {13},
	copyright = {2023 This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-28240-9},
	doi = {10.1038/s41598-023-28240-9},
	abstract = {Imagery from drones is becoming common in wildlife research and management, but processing data efficiently remains a challenge. We developed a methodology for training a convolutional neural network model on large-scale mosaic imagery to detect and count caribou (Rangifer tarandus), compare model performance with an experienced observer and a group of naïve observers, and discuss the use of aerial imagery and automated methods for large mammal surveys. Combining images taken at 75 m and 120 m above ground level, a faster region-based convolutional neural network (Faster-RCNN) model was trained in using annotated imagery with the labels: “adult caribou”, “calf caribou”, and “ghost caribou” (animals moving between images, producing blurring individuals during the photogrammetry processing). Accuracy, precision, and recall of the model were 80\%, 90\%, and 88\%, respectively. Detections between the model and experienced observer were highly correlated (Pearson: 0.96–0.99, P value {\textless} 0.05). The model was generally more effective in detecting adults, calves, and ghosts than naïve observers at both altitudes. We also discuss the need to improve consistency of observers’ annotations if manual review will be used to train models accurately. Generalization of automated methods for large mammal detections will be necessary for large-scale studies with diverse platforms, airspace restrictions, and sensor capabilities.},
	language = {en},
	number = {1},
	urldate = {2024-08-21},
	journal = {Scientific Reports},
	author = {Lenzi, Javier and Barnas, Andrew F. and ElSaid, Abdelrahman A. and Desell, Travis and Rockwell, Robert F. and Ellis-Felege, Susan N.},
	month = jan,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Ecology, Zoology, Computational biology and bioinformatics, Computational models, Engineering},
	pages = {947},
	file = {Full Text PDF:/Users/kirk/Zotero/storage/3ZAELQNT/Lenzi et al. - 2023 - Artificial intelligence for automated detection of large mammals creates path to upscale drone surve.pdf:application/pdf},
}
